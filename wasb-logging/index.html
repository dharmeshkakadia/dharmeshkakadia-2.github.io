<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <!-- mobile responsive meta -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Analyzing Azure Storage Performance</title>
  <meta name='description' content='Curious'>

  <link rel="canonical" href="/wasb-logging/">
  <link rel="alternate" type="application/rss+xml" title="Dharmesh Kakadia" href="/feed.xml">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@site_username">
  <meta name="twitter:creator" content="@creator_username">
  
    <meta name="twitter:title" content="Analyzing Azure Storage Performance">
  
  
    <meta name="twitter:url" content="/wasb-logging/">
  
  
    <meta name="twitter:description" content="Curious">
  
  
    <meta name="twitter:image:src" content="/path/to/image/logo.png">
  

  <!-- Main Stylesheet -->
  <link href="/assets/css/main.css" rel="stylesheet">

</head>


<body>

  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44808193-2', 'auto');
  ga('send', 'pageview');
</script>
  

  <div class="container-full">
  <!-- begin header -->
  <header class="header">

    <div class="logo">
      <a class="logo__link" href="/">
      
        <img class="logo__image" src=" /images/dharmesh.png" alt="Dharmesh Kakadia">
        Dharmesh Kakadia
      
      </a>
    </div>

    <nav class="main-nav">
      <span class="main-nav__open">
        <div style="width: 30px;height: 4px;background-color: black; margin: 5px 0;"></div>
        <div style="width: 30px;height: 4px;background-color: black; margin: 5px 0;"></div>
        <div style="width: 30px;height: 4px;background-color: black; margin: 5px 0;"></div>
      </span>

      <div class="main-nav__box">
        <span class="main-nav__close">Close</span>

        <ul class="nav__list list-reset">
          <li class="nav__item">
            <a href="/" class="nav__link">Home</a>
          </li>

          <li class="nav__item">
            <a href="/about" class="nav__link">About</a>
          </li>

          <li class="nav__item">
            <a href="/words/" class="nav__link">Quotes</a>
          </li>

          <li class="nav__item">
            <a href="/book/" class="nav__link">My Book</a>
          </li>


          <li class="nav__item">
            <a href="/talks" class="nav__link">Talks</a>
          </li>
          
        </ul>

      </div>

    </nav>

  </header>
  <!-- end header -->
</div>


  <!-- begin content -->
  <main class="content" aria-label="Content">
    <div class="container">
  <!-- begin post -->
  <article class="post">
    <div class="post__head" data-aos="fade-up" data-aos-easing="ease-out-quad" data-aos-duration="700">
      <h1 class="post__title">Analyzing Azure Storage Performance</h1>
      <div class="post__date">
        <time datetime="2017-12-25T00:00:00+00:00">Published Dec 25, 2017</time>
      </div>
      
    </div>

    <div class="post__content" data-aos="fade-up" data-aos-easing="ease-out-quad" data-aos-delay="100" data-aos-duration="700">
      <p>I work on performance of Big data systems at <a href="https://azure.microsoft.com/en-us/services/hdinsight/">Azure HDInsight</a> and as part of <a href="https://azure.microsoft.com/en-us/blog/hdinsight-interactive-query-performance-benchmarks-and-integration-with-power-bi-direct-query/">benchmarking</a>, many times I need to analyze the performance of the cloud storage. Performance of the storage system plays a very critical role in the performance of the cloud big data systems. Even though there are public benchmarks available for theses systems, its important to measure performance for your workload. In that spirit, we will see how to leverage storage logs for benchmarking your big data workload on <a href="https://azure.microsoft.com/en-us/services/storage/">Azure Storage Blob (aka WASB)</a>. We will see how to enable storage perf logging, how to download and analyze the logs and also how to combine this anlysis with query engines like Spark and Hive.</p>

<h2 id="downloading-and-analyzing-wasb-logs">Downloading and Analyzing WASB logs</h2>

<p>Azure Storage provides <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-analytics">logs and metrics</a> for all the requests. The logs are stored in the storage account in the following form <code class="language-plaintext highlighter-rouge">https://&lt;accountname&gt;.blob.core.windows.net/$logs/&lt;service-name&gt;/YYYY/MM/DD/hhmm/&lt;counter&gt;.log</code>. Although, this format for logs is simple, it can be quite challenging to build tools and automatation around this format - especially if you want to be efficient. This was one of my motivation behind writing <a href="https://github.com/dharmeshkakadia/azlogs">azlogs</a> - a tool for downloading logs for given timeperiod. I use it automatically <a href="https://github.com/hdinsight/HivePerformanceAutomation/blob/master/bin/perfdatascripts/getStoreLatency.sh">analyze latencies</a> of WASB requests.</p>

<p>Lets see how you can use azlogs to download the logs and anlayze them.</p>

<ol>
  <li>
    <p>Enable azure storage logging by following the <a href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/enabling-storage-logging-and-accessing-log-data">documentation</a>.</p>
  </li>
  <li>Download the azlogs tool.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> git clone https://github.com/dharmeshkakadia/azlogs <span class="o">&amp;&amp;</span> <span class="nb">cd </span>azlogs
</code></pre></div>    </div>
  </li>
  <li>Compile it using Maven.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> mvn package assembly:single 
</code></pre></div>    </div>
  </li>
  <li>Download the logs for a given time range. You need to provide the storage account name and access key along with start and end time for which you want to logs for.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Usage: azlogs &lt;AccountName&gt; &lt;AccountKey&gt; &lt;startDate<span class="o">(</span>seconds since epoch<span class="o">)&gt;</span> &lt;endDate<span class="o">(</span>seconds since epoch<span class="o">)&gt;</span> <span class="o">[</span>columns<span class="o">(</span>sorted<span class="o">)]</span>
</code></pre></div>    </div>
    <p>For example, to download the logs for storage account <code class="language-plaintext highlighter-rouge">storage1</code> from <code class="language-plaintext highlighter-rouge">1476132794</code> to <code class="language-plaintext highlighter-rouge">1476132895</code>, you can use the following command.</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> java <span class="nt">-jar</span> azlogs.jar storage1 <span class="nv">67t2Mw</span><span class="o">==</span> <span class="s2">"1476132794"</span> <span class="s2">"1476132895"</span> <span class="s2">"request_start_time,operation_type,end_to_end_latency_in_ms"</span> 2&gt;debug_logs <span class="o">&gt;</span> output
</code></pre></div>    </div>
  </li>
  <li>The above command will produce an output CSV file(delimited by ;) that you can use to analyze with your favorite data analysis tool. I like to use <a href="https://csvkit.readthedocs.io/en/1.0.1/">csvkit</a> for working with csv files on command line. It allows you to write a sql query against a csv file. For example, here is how to calculate <code class="language-plaintext highlighter-rouge">avg</code>,<code class="language-plaintext highlighter-rouge">min</code> and <code class="language-plaintext highlighter-rouge">max</code> latencies (from both client and service side) and the counts for various operations on WASB from above output logs using csvkit.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> csvsql <span class="nt">-d</span> <span class="s2">";"</span> <span class="nt">--query</span> <span class="s2">"select operation_type, count(*), avg(end_to_end_latency_in_ms), min(end_to_end_latency_in_ms), max(end_to_end_latency_in_ms), avg(server_latency_in_ms), min(server_latency_in_ms),max(server_latency_in_ms) from output group by operation_type"</span>
</code></pre></div>    </div>
    <p>This would produce output similar to :</p>

    <noscript><pre>400: Invalid request</pre></noscript>
    <script src="https://gist.github.com/a3080a2759a0ecefb7a0d99943239ec8.js"> </script>
  </li>
</ol>

<h2 id="analyzing-storage-performance-of-a-spark-or-hive-query">Analyzing storage performance of a Spark or hive query</h2>

<p>We can use the above technique to get the storage logs for a given spark or hive query/job. This is assuming the storage account is only being used by the given query. This is easily achievable in the benchmark or performance debugging scenarios.</p>

<p>At a high level, the steps for measureing the storage performance for a given spark/hive query:</p>

<ol>
  <li>Record the start time
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nv">STARTTIME</span><span class="o">=</span><span class="s2">"</span><span class="sb">`</span><span class="nb">date</span> +%s<span class="sb">`</span><span class="s2">"</span>
</code></pre></div>    </div>
  </li>
  <li>Execute spark or hive job(s).
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> spark-sql <span class="nt">-e</span> <span class="s2">"select count(*) from hivesampletable"</span>
</code></pre></div>    </div>
    <p>or if you are using hive</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> hive <span class="nt">-e</span> <span class="s2">"select count(*) from hivesampletable"</span>
</code></pre></div>    </div>
    <p>Note that, you can run arbitrary commands here that interact with storage.</p>
  </li>
  <li>Record the end time.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nv">ENDTIME</span><span class="o">=</span><span class="s2">"</span><span class="sb">`</span><span class="nb">date</span> +%s<span class="sb">`</span><span class="s2">"</span>
</code></pre></div>    </div>
  </li>
  <li>Download the storage logs from start time to end time using the steps mentioned above. This logs will contain all the storage requests made during this time frame.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> java <span class="nt">-jar</span> azlogs.jar storage1 <span class="nv">67t2Mw</span><span class="o">==</span> <span class="s2">"</span><span class="nv">$STARTTIME</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$ENDTIME</span><span class="s2">"</span> <span class="s2">"request_start_time,operation_type,end_to_end_latency_in_ms"</span> 2&gt;debug_logs <span class="o">&gt;</span> output
</code></pre></div>    </div>
  </li>
  <li>Anlayze the storage logs stored in <code class="language-plaintext highlighter-rouge">output</code> file.</li>
</ol>

<p>In the first section of this post, we saw how to calulate <code class="language-plaintext highlighter-rouge">avg</code>, <code class="language-plaintext highlighter-rouge">min</code> and <code class="language-plaintext highlighter-rouge">max</code> of storage request latecy. While these are useful statistical summaries, <a href="https://en.wikipedia.org/wiki/Quartile">quartiles</a> provide a much more useful descriptive statstics, especially in case of latency numbers. In performance analysis, we care about 99th, 99.9th, 99.99th percentile latencies very often.</p>

<p>We will now see how to calculate 99th percentile of storage requests. You can run the following command to generate 99th percentile latency numbers for different types of operations :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>csvsql <span class="nt">-d</span> <span class="s2">";"</span> <span class="nt">--query</span> <span class="s2">"select operation_type,E2E99thP from (select end_to_end_latency_in_ms,operation_type from output order by end_to_end_latency_in_ms asc limit cast(0.99*(select count(end_to_end_latency_in_ms) from output)as int)) group by operation_type"</span> 
</code></pre></div></div>

<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/b6c1b29cd899f31020f6ddc8e130882c.js"> </script>

<p>By changing <code class="language-plaintext highlighter-rouge">0.99</code> to in above query to <code class="language-plaintext highlighter-rouge">0.999</code> or <code class="language-plaintext highlighter-rouge">0.9999</code>, we can calcualte 99.9th or 99.99th percentile latency. We can combine the above queries to get a better picture of the requests success rates and latencies.</p>

<h2 id="analyzing-storage-performance-of-your-big-data-workload">Analyzing storage performance of your big data workload</h2>

<p>While measuring storage latencies for individual queries are useful for debugging query performance, if we want to get a more complete picture of storage and query engine performance on cloud, we should run industry standard benchmarks like <a href="https://github.com/dharmeshkakadia/tpch-hdinsight">tpch</a> and <a href="https://github.com/dharmeshkakadia/tpcds-hdinsight">tpcds</a> and see the storage reuqests numbers. With little more <a href="https://github.com/hdinsight/HivePerformanceAutomation">automation</a>, we can generate the following summary of storage requests across different queries:</p>

<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/7c2a3750298af7757ddde8714b84e3b5.js"> </script>

<p>Remember, storage is just one part of the query engines performance, if we want to understand the query engine performance at a deeper level, we need to combine this with other resource performance data - namely network, CPU, memory. In the next post we will see how to achieve that. Till then go measure your storage performance!</p>

    </div>

    

    <div class="post__share">
      <ul class="share__list list-reset">
        <li class="share__item">
          <a class="share__link share__twitter" href="https://twitter.com/intent/tweet?text=Analyzing%20Azure%20Storage%20Performance&via=dharmeshkakadia&url=/wasb-logging/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter" rel="nofollow">
              <svg enable-background="new 0 0 56.693 56.693" height="56.693" viewBox="0 0 56.693 56.693" width="56.693" xmlns="http://www.w3.org/2000/svg"><path d="m52.837 15.065c-1.811.805-3.76 1.348-5.805 1.591 2.088-1.25 3.689-3.23 4.444-5.592-1.953 1.159-4.115 2-6.418 2.454-1.843-1.964-4.47-3.192-7.377-3.192-5.581 0-10.106 4.525-10.106 10.107 0 .791.089 1.562.262 2.303-8.4-.422-15.848-4.445-20.833-10.56-.87 1.492-1.368 3.228-1.368 5.082 0 3.506 1.784 6.6 4.496 8.412-1.656-.053-3.215-.508-4.578-1.265-.001.042-.001.085-.001.128 0 4.896 3.484 8.98 8.108 9.91-.848.23-1.741.354-2.663.354-.652 0-1.285-.063-1.902-.182 1.287 4.015 5.019 6.938 9.441 7.019-3.459 2.711-7.816 4.327-12.552 4.327-.815 0-1.62-.048-2.411-.142 4.474 2.869 9.786 4.541 15.493 4.541 18.591 0 28.756-15.4 28.756-28.756 0-.438-.009-.875-.028-1.309 1.974-1.422 3.688-3.203 5.042-5.23z"/></svg>
            </a>
        </li>

      </ul>
    </div>

    <div class="post__navigation">
      
      <a class="prev" href="/openfaas-kubernetes/">
        <div class="prev__post-icon">
          <svg enable-background="new 0 0 512 512" height="512" viewBox="0 0 512 512" width="512" xmlns="http://www.w3.org/2000/svg"><path d="m352 128.4-32.3-32.4-159.7 160 159.7 160 32.3-32.4-127.3-127.6z"/></svg>
        </div>
        <span class="post__nav-wrapper">
          <div class="post__nav-image" style="background-image: url()"></div>
          <h2 class="post__nav-title"><time datetime="2017-12-25T00:00:00+00:00">Dec 25, 2017</time> <br>OpenFaaS on Minikube</h2>
        </span>
      </a>
      

      
      <a class="next" href="/presto-event-listener/">
        <div class="next__post-icon">
          <svg enable-background="new 0 0 512 512" height="512" viewBox="0 0 512 512" width="512" xmlns="http://www.w3.org/2000/svg"><path d="m160 128.4 32.3-32.4 159.7 160-159.7 160-32.3-32.4 127.3-127.6z"/></svg>
        </div>
        <span class="post__nav-wrapper">
          <div class="post__nav-image" style="background-image: url()"></div>
          <h2 class="post__nav-title"><time datetime="2017-12-25T00:00:00+00:00">Dec 25, 2017</time> <br>Write a Presto query logging plugin</h2>
        </span>
      </a>
      
    </div>

    

  </article>
  <!-- end post -->
</div>

  </main>
  <!-- end content -->

  <div class="container">
  <!-- begin footer -->
  <footer class="footer">
    <div class="footer__inner">
      <div class="contact">
        <div class="contact__title">Have a question where I can help? <a href="mailto:dharmesh.kakadia@gmail.com">Email me</a></div>
        <ul class="contact__list list-reset">
          
          <li class="contact__item">
            <a class="contact__link" href="https://twitter.com/dharmeshkakadia">Twitter</a>
          </li>
          
          <li class="contact__item">
            <a class="contact__link" href="https://facebook.com/dharmesh.kakadia">Facebook</a>
          </li>
          
          <li class="contact__item">
            <a class="contact__link" href="https://github.com/dharmeshkakadia">Github</a>
          </li>
          
          <li class="contact__item">
            <a class="contact__link" href="https://instagram.com/dharmeshkakadia">LinkedIn</a>
          </li>
          
        </ul>
      </div>
    </div>
  </footer>
  <!-- end footer -->
</div>


  <!-- begin js -->
  <script src="/assets/js/vendors/jquery-3.3.1.min.js"></script>
  <script src="/assets/js/vendors/aos.js"></script>
  <script src="/assets/js/vendors/jquery.fitvids.js"></script>
  <script src="/assets/js/common.js"></script>
  <!-- end js -->
</body>

</html>
